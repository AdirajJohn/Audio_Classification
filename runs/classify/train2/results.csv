                  epoch,             train/loss,  metrics/accuracy_top1,  metrics/accuracy_top5,               val/loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                0.65467,                    0.5,                      1,                0.68662,              4.284e-05,              4.284e-05,              4.284e-05
                      2,                0.63244,                0.86667,                      1,                0.67541,             8.8225e-05,             8.8225e-05,             8.8225e-05
                      3,                0.57267,                0.86667,                      1,                 0.6512,             0.00012866,             0.00012866,             0.00012866
                      4,                0.52369,                   0.85,                      1,                0.60956,             0.00016415,             0.00016415,             0.00016415
                      5,                0.52522,                0.88333,                      1,                0.54375,             0.00019469,             0.00019469,             0.00019469
                      6,                0.50792,                    0.9,                      1,                 0.5019,             0.00022029,             0.00022029,             0.00022029
                      7,                0.44147,                0.88333,                      1,                0.47271,             0.00024093,             0.00024093,             0.00024093
                      8,                0.36044,                0.88333,                      1,                0.46169,             0.00025663,             0.00025663,             0.00025663
                      9,                0.41592,                    0.9,                      1,                0.45559,             0.00026738,             0.00026738,             0.00026738
                     10,                  0.419,                0.88333,                      1,                0.45123,             0.00027318,             0.00027318,             0.00027318
                     11,                0.48448,                0.86667,                      1,                0.45355,             0.00027403,             0.00027403,             0.00027403
                     12,                0.42492,                0.91667,                      1,                0.45606,             0.00026994,             0.00026994,             0.00026994
                     13,                0.34792,                0.93333,                      1,                0.45919,              0.0002609,              0.0002609,              0.0002609
                     14,                0.41961,                    0.9,                      1,                 0.4653,              0.0002469,              0.0002469,              0.0002469
                     15,                0.52073,                0.91667,                      1,                0.44194,              0.0002192,              0.0002192,              0.0002192
                     16,                0.41907,                    0.9,                      1,                0.44008,              0.0002192,              0.0002192,              0.0002192
                     17,                0.34687,                    0.9,                      1,                0.43762,             0.00018385,             0.00018385,             0.00018385
                     18,                0.35486,                    0.9,                      1,                0.43908,             0.00014851,             0.00014851,             0.00014851
                     19,                0.30013,                0.91667,                      1,                 0.4387,             0.00011317,             0.00011317,             0.00011317
                     20,                0.26887,                    0.9,                      1,                 0.4286,             7.7826e-05,             7.7826e-05,             7.7826e-05
